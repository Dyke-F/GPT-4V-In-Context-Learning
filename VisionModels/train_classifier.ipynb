{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install timm\n",
    "# !{sys.executable} -m pip install torchvision\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import timm\n",
    "import ast\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# CHANGE HERE #######################################################################################################\n",
    "BASE_DIR = Path(\"CRC100K\")     # SET BASE_DIR HERE\n",
    "IMAGE_DIR = Path(\"./data/CRC-VAL-HE-7K-png\")  # SET IMAGE_DIR HERE\n",
    "# DATA_DIRECTORIES = [\"binary\", \"complete\", \"knn\"]\n",
    "DATA_DIRECTORIES = [\"knn\"]                                                     # SET DATA DIRECTORIES HERE\n",
    "# CHANGE HERE #######################################################################################################\n",
    "\n",
    "# MAKE NO CHANGES HERE\n",
    "VISION_MODELS = [\"resnet18\", \"resnet50\", \"tiny_vit_21m_224\", \"vit_small_patch8_224\"] \n",
    "BACKEND = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "NUM_EPOCHS = 10\n",
    "LR = 1e-3\n",
    "\n",
    "print(f\"Data directories: {DATA_DIRECTORIES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## DONT CHANGE ##########################################\n",
    "\n",
    "def run_train_test(experiment, VISION_MODEL, BACKEND, test_only=False):\n",
    "\n",
    "        model = timm.create_model(VISION_MODEL, pretrained=True, num_classes=num_classes)\n",
    "        print(\"Model # Parameters: \", sum([p.numel() for p in model.parameters() if p.requires_grad]))\n",
    "        model = model.to(BACKEND)\n",
    "        img_config = resolve_data_config({}, model=model)\n",
    "        img_transform = create_transform(**img_config)\n",
    "\n",
    "        test_label = torch.tensor(label_enc[experiment[\"label\"]])\n",
    "        test_image = img_transform(Image.open(IMAGE_DIR / experiment[\"img_path\"]))\n",
    "\n",
    "        if test_only:\n",
    "            loss = None\n",
    "\n",
    "        if not test_only:\n",
    "            train_images, train_labels = zip(*experiment[\"train_data\"].items())\n",
    "            train_images = torch.stack([img_transform(Image.open(IMAGE_DIR / img_path)) for img_path in train_images])\n",
    "            train_labels = torch.tensor([label_enc[label] for label in train_labels])\n",
    "\n",
    "            train_dataset = TensorDataset(train_images, train_labels)\n",
    "            train_dataloader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=True)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "            \n",
    "            model = model.train()\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                for images, labels in train_dataloader:\n",
    "                    images, labels = images.to(BACKEND), labels.to(BACKEND)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    sys.stdout.write(f\"\\rEpoch {epoch} Loss: {loss.item()}\")\n",
    "                    sys.stdout.flush()\n",
    "                    optimizer.step()\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        model = model.eval()\n",
    "        with torch.inference_mode():\n",
    "            test_image = test_image.to(BACKEND)\n",
    "            y_pred = model(test_image.unsqueeze(0)).squeeze(0)\n",
    "            y_pred_label = label_dec[y_pred.argmax().item()]\n",
    "        \n",
    "        sys.stdout.write(f\"Predicted: {y_pred_label}, Ground Truth: {label_dec[test_label.item()]}\")\n",
    "        sys.stdout.flush()\n",
    "        del model\n",
    "        return y_pred_label, loss.item() if isinstance(loss, torch.Tensor) else loss\n",
    "\n",
    "\n",
    "for VISION_MODEL in VISION_MODELS:\n",
    "    print(f\"Running {VISION_MODEL}...\")\n",
    "\n",
    "    for DATA_DIR in DATA_DIRECTORIES:\n",
    "        print(f\"Running {DATA_DIR}...\")\n",
    "\n",
    "        predictions_dir = BASE_DIR / \"predictions\" / DATA_DIR / VISION_MODEL\n",
    "        predictions_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        training_csvs = list(Path(BASE_DIR / DATA_DIR).glob(\"**/*.csv\"))\n",
    "        # training_csvs = [csv for csv in training_csvs if not \"zero_shot\" in csv.name]  # TODO: REMOVE THIS LINE ONCE DEBUGGED !!!!!!!\n",
    "\n",
    "        for train_csv in tqdm.tqdm(training_csvs, desc=\"Training Datasets\", colour=\"blue\"):\n",
    "\n",
    "            print(\"Training run on \", train_csv.name)\n",
    "            gpt_results = pd.read_csv(train_csv, index_col=0, header=0)\n",
    "            if not \"zero_shot\" in train_csv.name:\n",
    "                gpt_results[\"train_data\"] = gpt_results[\"train_data\"].map(ast.literal_eval)\n",
    "            gpt_results[\"img_path\"] = gpt_results[\"fname\"] + \".png\"\n",
    "\n",
    "            classes = sorted(set(gpt_results[\"label\"].to_list()))\n",
    "            num_classes = len(classes)\n",
    "            label_enc = {label: i for i, label in enumerate(classes)}\n",
    "            label_dec = {i: label for label, i in label_enc.items()}\n",
    "\n",
    "\n",
    "            for i, experiment in tqdm.tqdm(gpt_results.iterrows(), desc=\"Training Combinations\",\n",
    "                                           leave=False, colour=\"red\"):\n",
    "                            \n",
    "                if \"zero_shot\" in train_csv.name:\n",
    "                    y_pred_label, final_loss = run_train_test(experiment, VISION_MODEL, BACKEND, test_only=True)\n",
    "                \n",
    "                else:\n",
    "                    y_pred_label, final_loss = run_train_test(experiment, VISION_MODEL, BACKEND)\n",
    "\n",
    "                gpt_results.loc[i, \"answer\"] = y_pred_label\n",
    "                gpt_results.loc[i, \"final_loss\"] = final_loss\n",
    "\n",
    "            output_file = predictions_dir / train_csv.relative_to(BASE_DIR/DATA_DIR)\n",
    "\n",
    "            output_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "            gpt_results.to_csv(output_file)\n",
    "\n",
    "            accuracy = (gpt_results[\"label\"] == gpt_results[\"answer\"]).mean()\n",
    "            print(f\"{train_csv.name}: {accuracy:.2f}\")\n",
    "\n",
    "        print(f\"####################### Finished {DATA_DIR}. #######################\")\n",
    "    print(f\"####################### Finished {VISION_MODEL}. #######################\")\n",
    "print(f\"####################### Finished Run. #######################\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
