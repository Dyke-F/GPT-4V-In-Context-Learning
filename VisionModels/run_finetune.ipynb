{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from fewshot_histo.fewshot.feature_extractors import load_feature_extractor, FEATURE_EXTRACTORS\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"/app/data/CRC-100K-VIT/\")\n",
    "\n",
    "# Set feature extractor here!\n",
    "FEATURE_EXTRACTOR = \"phikon\"\n",
    "# FEATURE_EXTRACTOR = \"vit\"\n",
    "# FEATURE_EXTRACTOR = \"resnet50\"\n",
    "\n",
    "FEATURE_DIM = 768 if FEATURE_EXTRACTOR not in {\"resnet50\", \"retccl\", \"bt\", \"swav\", \"mocov2\"} else 2048\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "print(f\"Available feature extractors: {', '.join(FEATURE_EXTRACTORS.keys())}\")\n",
    "print(f\"Using feature extractor: {FEATURE_EXTRACTOR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = load_feature_extractor(FEATURE_EXTRACTOR)\n",
    "\n",
    "images = list(DATA_DIR.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Extract features\n",
    "with torch.no_grad():\n",
    "    features = {\n",
    "        image.name: feature_extractor(to_tensor(Image.open(image)).unsqueeze(0)).squeeze(0)\n",
    "        for image in tqdm(images, desc=\"Extracting features\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_experiment(train_features, test_feature):\n",
    "    classes = sorted(set(label for (_, label) in train_features))\n",
    "    label_enc = {label: i for i, label in enumerate(classes)}\n",
    "    label_dec = {i: label for i, label in enumerate(classes)}\n",
    "\n",
    "    train_feats = torch.stack(list(feat for (feat, _) in train_features))\n",
    "    train_labels_enc = torch.tensor([label_enc[label] for (_, label) in train_features])\n",
    "\n",
    "    model = nn.Linear(FEATURE_DIM, len(classes))\n",
    "\n",
    "    # Train model\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_feats)\n",
    "        loss = criterion(outputs, train_labels_enc)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f\"Epoch {epoch+1}/{10}, loss={loss.item():.4f}\")\n",
    "\n",
    "    # Test model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(test_feature.unsqueeze(0)).squeeze(0)\n",
    "        y_pred_label = label_dec[y_pred.argmax().item()]\n",
    "    return y_pred_label, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dir = DATA_DIR / \"binary\"\n",
    "predictions_dir = DATA_DIR / \"predictions\" / FEATURE_EXTRACTOR\n",
    "predictions_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "gpt_results_files = list(binary_dir.glob(\"**/*.csv\"))\n",
    "\n",
    "print(f\"Accuracy on GPT results files using linear classification head on features extracted by {feature_extractor.name}:\")\n",
    "\n",
    "for gpt_results_file in gpt_results_files:\n",
    "    if \"zero_shot\" in gpt_results_file.name:\n",
    "        continue\n",
    "    gpt_results = pd.read_csv(gpt_results_file, index_col=0, header=0)\n",
    "    gpt_results[\"train_data\"] = gpt_results[\"train_data\"].map(eval)\n",
    "\n",
    "    for i, experiment in gpt_results.iterrows():\n",
    "        test_label = experiment[\"label\"]\n",
    "        test_image = experiment[\"fname\"] + \".png\"\n",
    "        train_images = experiment[\"train_data\"]\n",
    "\n",
    "        # Get features of training and test images\n",
    "        train_features = [\n",
    "            (features[image], label)\n",
    "            for image, label in train_images.items()\n",
    "        ]\n",
    "        test_feature = features[test_image]\n",
    "\n",
    "        # Run experiment\n",
    "        pred_label, final_loss = run_train_experiment(train_features, test_feature)\n",
    "\n",
    "        gpt_results.loc[i, \"pred_label\"] = pred_label\n",
    "        gpt_results.loc[i, \"final_loss\"] = final_loss\n",
    "    \n",
    "    output_file = predictions_dir / gpt_results_file.relative_to(binary_dir)\n",
    "    output_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "    gpt_results.to_csv(output_file)\n",
    "\n",
    "    accuracy = (gpt_results[\"label\"] == gpt_results[\"pred_label\"]).mean()\n",
    "    print(f\"{gpt_results_file.name}: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
