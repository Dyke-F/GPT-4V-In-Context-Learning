{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from dataset import make_dataset_file\n",
    "import pydicom\n",
    "from pydicom import dcmread\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- KATHER CRC 100K -------- #\n",
    "\n",
    "\n",
    "def generate_crc100k_data(input_dir, output_dir, seed=42):\n",
    "    random.seed(seed)\n",
    "    input_dir = Path(input_dir).resolve()\n",
    "    crc100k_paths = list(Path(input_dir).glob('**/*.png'))\n",
    "    counts = Counter([str(p.stem).split(\"-\")[0] for p in crc100k_paths])\n",
    "\n",
    "    # get a random of 15 samples per class as test_samples\n",
    "    # use all others as random x-shot examples\n",
    "    test_samples = {}\n",
    "    x_shot_samples = {}\n",
    "    for k, _ in counts.items():\n",
    "        all_samples = list(Path(input_dir).glob(f'{k}-*.png'))\n",
    "        test_samples_list = random.sample(all_samples, 15) # ADJUST FOR A DIFFERERENT NUMBER OF SAMPLES\n",
    "        x_shot_samples_list = list(set(all_samples) - set(test_samples_list))\n",
    "\n",
    "        # Store just the file path as a string\n",
    "        test_samples[k] = [str(sample) for sample in test_samples_list]\n",
    "        x_shot_samples[k] = [str(sample) for sample in x_shot_samples_list]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    test_samples_df = pd.DataFrame([(k, v) for k, vs in test_samples.items() for v in vs], columns=['label', 'path'])\n",
    "    x_shot_samples_df = pd.DataFrame([(k, v) for k, vs in x_shot_samples.items() for v in vs], columns=['label', 'path'])\n",
    "    \n",
    "    test_samples_df[\"fname\"] = test_samples_df[\"path\"].apply(lambda x: Path(x).stem.split(\"/\")[-1])\n",
    "    x_shot_samples_df[\"fname\"] = x_shot_samples_df[\"path\"].apply(lambda x: Path(x).stem.split(\"/\")[-1])\n",
    "    test_samples_df[\"path\"] = test_samples_df.path.apply(lambda x: [x])\n",
    "    x_shot_samples_df[\"path\"] = x_shot_samples_df.path.apply(lambda x: [x])\n",
    "\n",
    "    test_samples_df = test_samples_df.reindex(columns=[\"fname\", \"label\", \"path\"])\n",
    "    x_shot_samples_df = x_shot_samples_df.reindex(columns=[\"fname\", \"label\", \"path\"])\n",
    "\n",
    "    test_samples_df.to_csv(f\"{output_dir}/test_samples.csv\", index=False)\n",
    "    x_shot_samples_df.to_csv(f\"{output_dir}/x_shot_samples.csv\", index=False)\n",
    "\n",
    "    return test_samples_df, x_shot_samples_df, counts\n",
    "\n",
    "#test_df, x_shot_ex_df, counts = generate_crc100k_data(input_dir=\"./data/CRC-VAL-HE-7K-png\", output_dir=\"./Datafiles/CRC100K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_more_crc100k_sample_data(existing_df_path, full_samples_df_path, seed=42):\n",
    "    existing = pd.read_csv(existing_df_path)\n",
    "    full = pd.read_csv(full_samples_df_path)\n",
    "    existing_images = existing[\"path\"].tolist()\n",
    "\n",
    "    filtered = full[~full[\"path\"].isin(existing_images)]\n",
    "\n",
    "    test_samples = filtered.groupby(\"label\").sample(15, random_state=seed)\n",
    "    test_samples.to_csv(f\"./Datafiles/CRC100K/test_samples_complete.csv\", index=False)\n",
    "\n",
    "\n",
    "# generate_more_crc100k_sample_data(\"./Datafiles/CRC100K/prompt_samples.csv\", \"./Datafiles/CRC100K/all_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"./Datafiles/CRC100K/test_samples_complete.csv\")\n",
    "prompt = pd.read_csv(\"./Datafiles/CRC100K/prompt_samples.csv\")\n",
    "\n",
    "set(test.fname) & set(prompt.fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- PATCH CAMELYON -------- #\n",
    "\n",
    "\n",
    "def generate_pcam_data(input_dir, output_dir, seed=42):\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    input_dir = Path(input_dir).resolve()\n",
    "    paths = list(input_dir.rglob(\"*.h5\"))\n",
    "    images = [p for p in paths if \"test_x\" in str(p)][0]\n",
    "    labels = [p for p in paths if \"test_y\" in str(p)][0]\n",
    "\n",
    "    with h5py.File(images, \"r\") as h5imgs:\n",
    "        images = h5imgs[\"x\"][:]\n",
    "\n",
    "    with h5py.File(labels, \"r\") as h5labels:\n",
    "        labels = h5labels[\"y\"][:]\n",
    "\n",
    "    flattened_labels = labels.flatten()\n",
    "\n",
    "    # check that we are writing into an empty directory\n",
    "    img_dir = input_dir.parent / \"full_imgs\"\n",
    "    \n",
    "    if os.path.exists(img_dir):\n",
    "        shutil.rmtree(img_dir)\n",
    "\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.makedirs(img_dir)\n",
    "\n",
    "    label_map = {1: \"TUM\", 0: \"NORM\"}\n",
    "\n",
    "    test_samples = []\n",
    "    for sidx, (img, label) in enumerate(zip(images, flattened_labels, strict=True)):\n",
    "        img = Image.fromarray(img)\n",
    "        fname = f\"{label_map[label]}-PCAM-{sidx}\"\n",
    "        save_name = f\"{img_dir}/{fname}.png\"\n",
    "        img.save(save_name)\n",
    "        test_samples.append([fname, label_map[label], [save_name]])\n",
    "\n",
    "    full_samples = pd.DataFrame(test_samples, columns=[\"fname\", \"label\", \"path\"])\n",
    "    full_samples.to_csv(input_dir.parent / \"pcam_full_samples.csv\", index=False)\n",
    "    test_samples = full_samples.groupby(\"label\").sample(15, random_state=seed)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    test_samples.to_csv(f\"{output_dir}/pcam_test_samples.csv\", index=False)\n",
    "    return test_samples\n",
    "\n",
    "# test_samples = generate_pcam_data(\"./data/PCam/h5s\", output_dir=\"./Datafiles/PCam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_more_pcam_sample_data(existing_df_path, full_samples_df_path, seed=42):\n",
    "    existing = pd.read_csv(existing_df_path)\n",
    "    full = pd.read_csv(full_samples_df_path)\n",
    "    existing_images = existing[\"path\"].tolist()\n",
    "\n",
    "    filtered = full[~full[\"path\"].isin(existing_images)]\n",
    "\n",
    "    test_samples = filtered.groupby(\"label\").sample(15, random_state=seed)\n",
    "    test_samples.to_csv(f\"./Datafiles/PCam/pcam_test_samples2.csv\", index=False)\n",
    "\n",
    "# generate_more_pcam_sample_data(\"./Datafiles/PCam/pcam_test_samples.csv\",\n",
    "#                           \"./data/PCam/pcam_full_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"...csv\")\n",
    "# df.rename(columns={\"label\": \"orig_label\"}, inplace=True)\n",
    "# df[\"label\"] = df.orig_label.map({1: \"TUM\", 0: \"NORM\"})\n",
    "# df.to_csv(\"....csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- MHIST CAMELYON -------- #\n",
    "\n",
    "def prepend_labels_to_imgs(input_dir, annotations_path):\n",
    "    annotations = pd.read_csv(annotations_path)\n",
    "    for img_path in Path(input_dir).glob(\"*.png\"):\n",
    "        label_row = annotations[annotations[\"Image Name\"] == img_path.name]\n",
    "        prefix = label_row[\"Majority Vote Label\"].iloc[0]\n",
    "        new_name = prefix + \"_\" + img_path.name\n",
    "        img_path.rename(img_path.with_name(new_name))\n",
    "        annotations.loc[annotations[\"Image Name\"] == img_path.name, \"Image Name\"] = new_name\n",
    "    annotations.to_csv(annotations_path, index=False)\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "def generate_mhist_data(input_dir, output_dir, seed=42, simplify=True):\n",
    "    random.seed(seed)\n",
    "    input_dir = Path(input_dir).resolve()\n",
    "    paths = list(input_dir.glob(\"*.png\"))\n",
    "\n",
    "    if simplify:\n",
    "        annotations = pd.read_csv(\"./data/MHIST/annotations.csv\")\n",
    "        hp_imgs = annotations.query(\"`Majority Vote Label` == 'HP' and `Number of Annotators who Selected SSA (Out of 7)` == 0\")[\"Image Name\"].tolist()\n",
    "        ssa_imgs = annotations.query(\"`Majority Vote Label` == 'SSA' and `Number of Annotators who Selected SSA (Out of 7)` == 7\")[\"Image Name\"].tolist()\n",
    "\n",
    "    else:\n",
    "        hp_imgs = [p for p in paths if str(p.name).startswith(\"HP\")]\n",
    "        ssa_imgs = [p for p in paths if str(p.name).startswith(\"SSA\")]\n",
    "    \n",
    "    hp_samples = random.sample(hp_imgs, 15)\n",
    "    ssa_samples = random.sample(ssa_imgs, 15)\n",
    "    samples = hp_samples + ssa_samples\n",
    "\n",
    "    samples = [[Path(p).stem, Path(p).stem.split(\"_\")[0], [os.path.join(input_dir, p)]] for p in samples]\n",
    "    samples_df = pd.DataFrame(samples, columns=[\"fname\", \"label\", \"path\"])\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    samples_df.to_csv(f\"{output_dir}/mhist_samples.csv\", index=False)\n",
    "\n",
    "    annotations[\"fname\"] = annotations[\"Image Name\"].apply(lambda x: Path(x).stem)\n",
    "    annotations[\"label\"] = annotations[\"Image Name\"].apply(lambda x: str(x).split(\"_\")[0])\n",
    "    annotations[\"path\"] = annotations[\"Image Name\"].apply(lambda x: [os.path.join(input_dir, x)])\n",
    "    annotations[[\"fname\", \"label\", \"path\"]].to_csv(\"./mhist_full_samples.csv\", index=False)\n",
    "\n",
    "# prepend_labels_to_imgs(\"./data/MHIST/images\", \"./data/MHIST/annotations.csv\")\n",
    "# generate_mhist_data(\"./data/MHIST/images\", \"./Datafiles/MHIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_more_mhist_sample_data(existing_df_path, full_samples_df_path, seed=42):\n",
    "    existing = pd.read_csv(existing_df_path)\n",
    "    full = pd.read_csv(full_samples_df_path)\n",
    "    existing_images = existing[\"path\"].tolist()\n",
    "    filtered = full[~full[\"path\"].isin(existing_images)]\n",
    "    test_samples = filtered.groupby(\"label\").sample(15, random_state=seed)\n",
    "    test_samples.to_csv(f\"./Datafiles/MHIST/test_samples.csv\", index=False)\n",
    "\n",
    "# generate_more_mhist_sample_data(\"./Datafiles/MHIST/mhist_samples.csv\",\n",
    "#                           \"./data/MHIST/mhist_full_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the MSSI image names\n",
    "# originally those are in 2 folders called MSIMUT and MSS\n",
    "# to the images in MSIMUT prepend MSI\n",
    "# to the images in MSS prepend MSS\n",
    "# this will make label extraction for knn sampling easier\n",
    "\n",
    "# Set your paths here\n",
    "msimut_path = \"\"\n",
    "mss_path = \"\"\n",
    "\n",
    "def prepend_labels_to_imgs(input_dir, prefix):\n",
    "    for img_path in Path(input_dir).glob(\"*.png\"):\n",
    "        new_name = prefix + \"_\" + img_path.name\n",
    "        img_path.rename(img_path.with_name(new_name))\n",
    "    print(\"Done.\")\n",
    "\n",
    "prepend_labels_to_imgs(msimut_path, \"MSI\")\n",
    "prepend_labels_to_imgs(mss_path, \"MSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CMMD -------- #\n",
    "# !{sys.executable} -m pip install pydicom\n",
    "\n",
    "\n",
    "def process_metadata(clini_path):\n",
    "    clini_df = pd.read_excel(clini_path, engine=\"openpyxl\")\n",
    "    sampled_df = clini_df.groupby(\"classification\").sample(15, random_state=42)\n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "def process_dicoms(image_path, dicom_df, output_folder, verbose=False):\n",
    "\n",
    "    def load_and_save_dicom(dicom_file, dicom_lr):\n",
    "        ds = pydicom.dcmread(dicom_file)\n",
    "        # skip wrong side\n",
    "        if ds.ImageLaterality == dicom_lr:\n",
    "            if hasattr(ds, \"pixel_array\"):\n",
    "                image = Image.fromarray(ds.pixel_array)\n",
    "                if verbose:\n",
    "                    plt.imshow(ds.pixel_array, cmap=plt.cm.bone)\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.show()\n",
    "\n",
    "                relative_path = dicom_file.relative_to(image_path.parent)\n",
    "                output_path = output_folder / relative_path.with_suffix(\".png\")\n",
    "                output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                image.save(output_path)\n",
    "                return output_path\n",
    "\n",
    "    cmmd_test_samples = defaultdict(lambda: {\"path\": [], \"label\": \"\"})\n",
    "    \n",
    "    for _, sample in dicom_df.iterrows():\n",
    "        dicom_path = sample.path\n",
    "        dicom_lr = sample.LeftRight\n",
    "        dicom_files = list(Path(dicom_path).rglob(\"*.dcm\"))\n",
    "        \n",
    "        cmmd_test_samples[sample.ID1][\"label\"] = sample.classification\n",
    "        for dicom_file in dicom_files:\n",
    "            output_path = load_and_save_dicom(dicom_file, dicom_lr)\n",
    "            if output_path is not None:\n",
    "                cmmd_test_samples[sample.ID1][\"path\"].append(output_path)\n",
    "        cmmd_test_samples[sample.ID1][\"path\"].sort()\n",
    "    \n",
    "    return cmmd_test_samples\n",
    "\n",
    "\n",
    "def generate_cmmd_data(clini_path, image_path, output_dir):\n",
    "    sampled_df = process_metadata(clini_path)\n",
    "    # dicom_paths = sampled_df.ID1.to_list()\n",
    "    dicom_df = sampled_df[[\"ID1\", \"LeftRight\", \"classification\"]]\n",
    "    dicom_df[\"path\"] = dicom_df[\"ID1\"].apply(lambda x: f\"{image_path}/{x}\")\n",
    "    cmmd_test_samples = process_dicoms(image_path, dicom_df, output_dir, verbose=False)\n",
    "    sampled_df = pd.DataFrame.from_dict(cmmd_test_samples, orient=\"index\").reset_index(names=\"fname\")\n",
    "    sampled_df = sampled_df.reindex(columns=[\"fname\", \"label\", \"path\"])\n",
    "    if not os.path.exists(\"./Datafiles/CMMD/\"):\n",
    "        os.makedirs(\"./Datafiles/CMMD/\")\n",
    "    sampled_df.to_csv(f\"./Datafiles/CMMD/cmmd_sampled_data.csv\", index=False)\n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "clini_path = \"./data/CMMD/CMMD_clinicaldata_revision.xlsx\"\n",
    "image_path = Path(\"./data/CMMD/CMMD\")\n",
    "output_dir = Path(\"./data/CMMD/selected_imgs\")\n",
    "# s = generate_cmmd_data(clini_path, image_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- MSSI -------- #\n",
    "\n",
    "def generate_mssi_data(input_mss, input_msi, output_dir, seed=42, n_pats=15, n_tiles=10):\n",
    "    random.seed(42)\n",
    "    input_mss = Path(input_mss).resolve()\n",
    "    input_msi = Path(input_msi).resolve()\n",
    "    mss_paths = list(Path(input_mss).glob('**/*.png'))\n",
    "    msi_paths = list(Path(input_msi).glob('**/*.png'))\n",
    "\n",
    "    # these are the 15 patients we will use for testing for MSI vs MSS\n",
    "\n",
    "    patient_id_regex = \"TCGA-..-....\"\n",
    "    mss_patients = set([re.search(patient_id_regex, str(path)).group() for path in mss_paths])\n",
    "    msi_patients = set([re.search(patient_id_regex, str(path)).group() for path in msi_paths])\n",
    "\n",
    "    mss = {}\n",
    "    for pat in mss_patients:\n",
    "        mss[pat] = [str(p) for p in mss_paths if pat in str(p)]\n",
    "    mss_records = [(patient, path) for patient, paths in mss.items() for path in paths]\n",
    "\n",
    "    msi = {}\n",
    "    for pat in msi_patients:\n",
    "        msi[pat] = [str(p) for p in msi_paths if pat in str(p)]\n",
    "    msi_records = [(patient, path) for patient, paths in msi.items() for path in paths]\n",
    "    \n",
    "    mss_df = pd.DataFrame(mss_records, columns=[\"patient\", \"path\"])\n",
    "    mss_df[\"label\"] = \"MSS\"\n",
    "    mss_df = mss_df.groupby(\"patient\").agg({\"path\":list, \"label\": \"first\", \"patient\": \"first\"})\n",
    "\n",
    "    msi_df = pd.DataFrame(msi_records, columns=[\"patient\", \"path\"])\n",
    "    msi_df[\"label\"] = \"MSI\"\n",
    "    msi_df = msi_df.groupby(\"patient\").agg({\"path\":list, \"label\": \"first\", \"patient\": \"first\"})\n",
    "\n",
    "    df = pd.concat([mss_df, msi_df])\n",
    "    df[\"fname\"] = df[\"path\"].apply(lambda x: [Path(fp).stem.split(\"/\")[-1] for fp in x])\n",
    "\n",
    "    # sample 15 patients\n",
    "    sampled_df = df.groupby(\"label\").sample(n=n_pats, random_state=seed, replace=False)\n",
    "    # sample 10 random tiles\n",
    "\n",
    "    def sample_tiles(lst):\n",
    "        max_len = len(lst)\n",
    "        num_samples = min(n_tiles, max_len)\n",
    "        return random.sample(range(max_len), num_samples)\n",
    "    \n",
    "    sample_indices_per_row = sampled_df[\"path\"].apply(sample_tiles)\n",
    "    for i, tiles_per_row in enumerate(sample_indices_per_row):\n",
    "        row_idx = sampled_df.index[i]\n",
    "\n",
    "        # Assuming 'path' and 'fname' are lists within each cell of the DataFrame\n",
    "        new_path = [sampled_df.at[row_idx, 'path'][idx] for idx in tiles_per_row]\n",
    "        new_fname = [sampled_df.at[row_idx, 'fname'][idx] for idx in tiles_per_row]\n",
    "\n",
    "        # Update the entire row with the new lists\n",
    "        sampled_df.at[row_idx, 'path'] = new_path\n",
    "        sampled_df.at[row_idx, 'fname'] = new_fname\n",
    "\n",
    "    sampled_df.to_csv(f\"{output_dir}/mssi_samples.csv\", index=False)\n",
    "\n",
    "    return sampled_df, sample_indices_per_row\n",
    "\n",
    "\n",
    "### Set your paths here\n",
    "msi_path = \"\"\n",
    "mss_path = \"\"\n",
    "\n",
    "df, idx = generate_mssi_data(mss_path, msi_path, \"./Datafiles/MSSI\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### merge MSI Mut and MSS train and test data\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# src = \"/Users/dykeferber/Downloads/MSS 2\"\n",
    "# dest = \"/Users/dykeferber/Desktop/GPT4VMed/data/MSSI/MSS\"\n",
    "\n",
    "# for f in os.listdir(src):\n",
    "#     shutil.move(os.path.join(src, f), dest)\n",
    "\n",
    "# src = \"/Users/dykeferber/Downloads/MSIMUT 2\"\n",
    "# dest = \"/Users/dykeferber/Desktop/GPT4VMed/data/MSSI/MSIMUT\"\n",
    "\n",
    "# for f in os.listdir(src):\n",
    "#     shutil.move(os.path.join(src, f), dest)\n",
    "\n",
    "# msst = os.listdir(\"/Users/dykeferber/Desktop/GPT4VMed/data/MSSI/MSS\")\n",
    "# msit = os.listdir(\"/Users/dykeferber/Desktop/GPT4VMed/data/MSSI/MSIMUT\")\n",
    "\n",
    "# print(len(msst), len(msit))\n",
    "\n",
    "# msstest = os.listdir(\"/Users/dykeferber/Downloads/MSS 2\")\n",
    "# msitest = os.listdir(\"/Users/dykeferber/Downloads/MSIMUT 2\")\n",
    "\n",
    "# print(len(msstest), len(msitest))\n",
    "\n",
    "# assert len(os.listdir(\"/Users/dykeferber/Desktop/GPT4VMed/data/MSSI/MSS\")) == len(msst+msstest)\n",
    "# assert len(os.listdir(\"/Users/dykeferber/Desktop/GPT4VMed/data/MSSI/MSIMUT\")) == len(msit+msitest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
